{
  "annotations": {
    "list": []
  },
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 0,
  "id": null,
  "links": [],
  "liveNow": false,
  "panels": [
    {
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {"color": "green", "value": null},
              {"color": "yellow", "value": 500},
              {"color": "red", "value": 1000}
            ]
          },
          "unit": "ms"
        },
        "overrides": []
      },
      "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0},
      "id": 1,
      "options": {
        "legend": {
          "calcs": ["mean", "max"],
          "displayMode": "table",
          "placement": "bottom"
        },
        "tooltip": {"mode": "multi"}
      },
      "targets": [
        {
          "expr": "histogram_quantile(0.50, sum(rate(inference_time_to_first_token_seconds_bucket[1m])) by (le, tenant)) * 1000",
          "legendFormat": "{{tenant}} p50",
          "refId": "A"
        },
        {
          "expr": "histogram_quantile(0.99, sum(rate(inference_time_to_first_token_seconds_bucket[1m])) by (le, tenant)) * 1000",
          "legendFormat": "{{tenant}} p99",
          "refId": "B"
        }
      ],
      "title": "Time to First Token (TTFT)",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {"color": "red", "value": null},
              {"color": "yellow", "value": 10},
              {"color": "green", "value": 20}
            ]
          },
          "unit": "tokps"
        },
        "overrides": []
      },
      "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0},
      "id": 2,
      "options": {
        "legend": {
          "calcs": ["mean", "max"],
          "displayMode": "table",
          "placement": "bottom"
        },
        "tooltip": {"mode": "multi"}
      },
      "targets": [
        {
          "expr": "histogram_quantile(0.50, sum(rate(inference_tokens_per_second_bucket[1m])) by (le, tenant))",
          "legendFormat": "{{tenant}} p50",
          "refId": "A"
        },
        {
          "expr": "histogram_quantile(0.95, sum(rate(inference_tokens_per_second_bucket[1m])) by (le, tenant))",
          "legendFormat": "{{tenant}} p95",
          "refId": "B"
        }
      ],
      "title": "Tokens per Second",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {"color": "green", "value": null},
              {"color": "yellow", "value": 2},
              {"color": "red", "value": 5}
            ]
          },
          "unit": "s"
        },
        "overrides": []
      },
      "gridPos": {"h": 8, "w": 12, "x": 0, "y": 8},
      "id": 3,
      "options": {
        "legend": {
          "calcs": ["mean", "max"],
          "displayMode": "table",
          "placement": "bottom"
        },
        "tooltip": {"mode": "multi"}
      },
      "targets": [
        {
          "expr": "histogram_quantile(0.50, sum(rate(inference_request_latency_seconds_bucket{status=\"success\"}[1m])) by (le, tenant))",
          "legendFormat": "{{tenant}} p50",
          "refId": "A"
        },
        {
          "expr": "histogram_quantile(0.95, sum(rate(inference_request_latency_seconds_bucket{status=\"success\"}[1m])) by (le, tenant))",
          "legendFormat": "{{tenant}} p95",
          "refId": "B"
        },
        {
          "expr": "histogram_quantile(0.99, sum(rate(inference_request_latency_seconds_bucket{status=\"success\"}[1m])) by (le, tenant))",
          "legendFormat": "{{tenant}} p99",
          "refId": "C"
        }
      ],
      "title": "Request Latency",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {"color": "green", "value": null},
              {"color": "yellow", "value": 5000},
              {"color": "red", "value": 10000}
            ]
          },
          "unit": "decmbytes"
        },
        "overrides": []
      },
      "gridPos": {"h": 8, "w": 12, "x": 12, "y": 8},
      "id": 4,
      "options": {
        "legend": {
          "calcs": ["mean", "max"],
          "displayMode": "table",
          "placement": "bottom"
        },
        "tooltip": {"mode": "multi"}
      },
      "targets": [
        {
          "expr": "ollama_memory_mb",
          "legendFormat": "Ollama Memory",
          "refId": "A"
        }
      ],
      "title": "Ollama Memory Usage",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {"color": "green", "value": null}
            ]
          },
          "unit": "short"
        },
        "overrides": []
      },
      "gridPos": {"h": 4, "w": 8, "x": 0, "y": 16},
      "id": 8,
      "options": {
        "colorMode": "value",
        "graphMode": "none",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": ["sum"],
          "fields": "",
          "values": false
        },
        "textMode": "auto"
      },
      "targets": [
        {
          "expr": "sum(increase(inference_tokens_generated_total{type=\"completion\"}[5m]))",
          "legendFormat": "Tokens",
          "refId": "A"
        }
      ],
      "title": "Tokens Generated (5m)",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {"color": "green", "value": null}
            ]
          },
          "unit": "short"
        },
        "overrides": []
      },
      "gridPos": {"h": 4, "w": 8, "x": 8, "y": 16},
      "id": 9,
      "options": {
        "colorMode": "value",
        "graphMode": "none",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": ["sum"],
          "fields": "",
          "values": false
        },
        "textMode": "auto"
      },
      "targets": [
        {
          "expr": "sum(increase(inference_request_latency_seconds_count[5m]))",
          "legendFormat": "Requests",
          "refId": "A"
        }
      ],
      "title": "Total Requests (5m)",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {"color": "green", "value": null},
              {"color": "yellow", "value": 5},
              {"color": "red", "value": 10}
            ]
          },
          "unit": "percent"
        },
        "overrides": []
      },
      "gridPos": {"h": 4, "w": 8, "x": 16, "y": 16},
      "id": 10,
      "options": {
        "colorMode": "value",
        "graphMode": "none",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": ["lastNotNull"],
          "fields": "",
          "values": false
        },
        "textMode": "auto"
      },
      "targets": [
        {
          "expr": "sum(increase(inference_request_latency_seconds_count{status!=\"success\"}[5m])) / sum(increase(inference_request_latency_seconds_count[5m])) * 100",
          "legendFormat": "Error Rate",
          "refId": "A"
        }
      ],
      "title": "Error Rate (5m)",
      "type": "stat"
    }
  ],
  "refresh": "5s",
  "schemaVersion": 38,
  "style": "dark",
  "tags": ["inference", "llm"],
  "templating": {
    "list": []
  },
  "time": {
    "from": "now-15m",
    "to": "now"
  },
  "timepicker": {},
  "timezone": "",
  "title": "LLM Inference Gateway",
  "uid": "llm-inference",
  "version": 1,
  "weekStart": ""
}
